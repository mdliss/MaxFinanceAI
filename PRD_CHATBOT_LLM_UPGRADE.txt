# Product Requirements Document: AI-Powered Financial Chatbot Upgrade

## 1. EXECUTIVE SUMMARY

### 1.1 Project Overview
Upgrade the existing rule-based financial chatbot to use a Large Language Model (LLM) for natural language understanding and personalized financial guidance. This enhancement will transform the chatbot from a limited pattern-matching system to an intelligent assistant capable of understanding complex financial questions and providing personalized, data-driven advice.

### 1.2 Current State
- Rule-based chatbot with ~140 lines of if/else logic (FinancialChatbot.tsx:62-202)
- Handles only predefined question patterns (credit, income, spending, subscriptions, emergency fund)
- Limited flexibility - cannot answer variations or complex multi-part questions
- All logic client-side - no backend API integration
- Simulated 800ms delay to mimic processing
- Uses existing user profile data (signals, personas, recommendations, transactions)

### 1.3 Target State
- LLM-powered backend API endpoint for chat processing
- Natural language understanding for ANY financial question
- Real-time access to user's transaction history, spending patterns, signals, and recommendations
- Conversational memory (multi-turn conversations)
- Streaming responses for better UX
- Comprehensive logging and analytics
- Guardrails for responsible financial advice
- Support for both Claude (Anthropic) and OpenAI GPT-4

### 1.4 Success Metrics
- Chat response time < 3 seconds (p95)
- 95%+ question comprehension rate
- 90%+ user satisfaction with advice quality
- Zero financial compliance violations
- 50%+ reduction in "I don't understand" responses
- 3x increase in chat engagement (messages per session)

---

## 2. PROBLEM STATEMENT

### 2.1 User Pain Points
1. **Limited Question Coverage**: Users can only ask ~7 predefined question types
2. **No Transaction Search**: Cannot ask "How much did I spend at Starbucks?" or "Show my Amazon purchases"
3. **No Comparative Analysis**: Cannot ask "Is my spending higher this month than last month?"
4. **No Complex Reasoning**: Cannot handle "Should I pay off debt or save more?" type questions
5. **Rigid Responses**: Same canned responses for similar questions
6. **No Follow-up Understanding**: Cannot continue conversations or ask clarifying questions

### 2.2 Business Impact
- Low chat engagement (users abandon after 1-2 messages)
- Users cannot discover insights from their data
- Competitive disadvantage (other fintech apps have AI assistants)
- Underutilized transaction/signal data
- Missed opportunity for financial education

### 2.3 Technical Debt
- Client-side business logic difficult to update
- No centralized chat API for future integrations
- Cannot A/B test different response strategies
- No analytics on question types or user satisfaction
- Hardcoded responses mixed with UI code

---

## 3. GOALS AND OBJECTIVES

### 3.1 Primary Goals
1. **Enable Natural Language Financial Queries**: Users can ask questions in their own words
2. **Provide Data-Driven Personalized Advice**: Leverage actual transaction/signal data for insights
3. **Build Scalable Chat Infrastructure**: Backend API that can support future AI features
4. **Maintain Financial Responsibility**: Implement guardrails to avoid risky/illegal advice

### 3.2 Secondary Goals
1. **Support Multiple LLM Providers**: Claude and OpenAI with easy switching
2. **Enable Conversation Memory**: Multi-turn conversations with context
3. **Add Streaming Responses**: Better UX for long responses
4. **Implement Analytics**: Track question types, satisfaction, errors
5. **Support Transaction Search**: Natural language queries for spending data

### 3.3 Non-Goals (Out of Scope)
- Voice interface
- Multi-language support (English only for v1)
- Integration with external financial data sources
- Automated trading/investment execution
- Tax preparation or legal advice
- Credit score monitoring integration

---

## 4. USER STORIES

### 4.1 Core User Stories

**US-1: Natural Language Questions**
- As a user, I want to ask financial questions in my own words
- So that I don't have to guess the right keywords
- Acceptance: Any reasonable financial question gets a relevant response

**US-2: Transaction Insights**
- As a user, I want to ask "How much did I spend on coffee this month?"
- So that I can understand my spending patterns without manual calculation
- Acceptance: Accurate sum of coffee-related transactions with breakdown

**US-3: Personalized Recommendations**
- As a user, I want advice based on MY actual spending data
- So that recommendations are relevant to my situation
- Acceptance: Responses reference actual transactions, amounts, and patterns

**US-4: Multi-Turn Conversations**
- As a user, I want to ask follow-up questions
- So that I can have a natural conversation
- Acceptance: Chatbot remembers previous 5 messages in conversation

**US-5: Fast Responses**
- As a user, I want responses in under 3 seconds
- So that the chat feels responsive and natural
- Acceptance: P95 response time < 3000ms

### 4.2 Advanced User Stories

**US-6: Comparative Analysis**
- As a user, I want to compare spending across time periods
- Example: "Am I spending more on dining this month vs last month?"
- Acceptance: Accurate comparison with percentage change

**US-7: Subscription Management**
- As a user, I want to discover all my subscriptions
- Example: "What subscriptions do I have?"
- Acceptance: List all recurring charges with amounts and last charge date

**US-8: Budget Tracking**
- As a user, I want to know if I'm on track with my budget
- Example: "Am I over budget in Shopping?"
- Acceptance: Shows current spend vs budget with days remaining in month

**US-9: Financial Education**
- As a user, I want to learn financial concepts
- Example: "What's the debt avalanche method?"
- Acceptance: Clear explanation with examples using my data when relevant

**US-10: Recommendation Exploration**
- As a user, I want to understand my personalized recommendations
- Example: "Why should I pay down my credit card?"
- Acceptance: Explains the recommendation with data-driven rationale

---

## 5. TECHNICAL REQUIREMENTS

### 5.1 Architecture

**Backend API (FastAPI)**
- New router: `/api/v1/chat`
- Endpoints:
  - POST `/chat/message` - Send message, get response
  - POST `/chat/stream` - Send message, get streaming response
  - GET `/chat/history/{user_id}` - Get conversation history
  - DELETE `/chat/history/{user_id}` - Clear conversation history
  - POST `/chat/feedback` - Submit feedback on response

**Database Schema Additions**
- New table: `chat_messages`
  - message_id (PK)
  - user_id (FK)
  - conversation_id (UUID)
  - role (user/assistant/system)
  - content (TEXT)
  - tokens_used (INT)
  - response_time_ms (INT)
  - model_used (VARCHAR)
  - timestamp (DATETIME)

- New table: `chat_feedback`
  - feedback_id (PK)
  - message_id (FK)
  - user_id (FK)
  - rating (1-5)
  - feedback_text (TEXT)
  - timestamp (DATETIME)

**LLM Integration**
- Support for Claude (Anthropic) as primary
- Support for OpenAI GPT-4 as fallback
- Configurable via environment variables
- Retry logic with exponential backoff
- Rate limiting per user (20 messages/hour)

### 5.2 Data Context Building

**User Context Components**
1. **Profile Data**:
   - Name, age, income level
   - Account balances (checking, savings, credit cards)
   - Credit utilization percentage
   - Income stability signals

2. **Transaction Data**:
   - Recent 30 days of transactions (up to 100)
   - Spending by category (last 30 days)
   - Largest transactions this month
   - Recurring charges detected

3. **Behavioral Signals**:
   - All active signals (credit_utilization, spending_surge, etc.)
   - Signal values and details
   - Trend direction (improving/worsening)

4. **Recommendations**:
   - Approved recommendations only
   - Title, description, rationale, persona type
   - Sorted by priority

5. **Personas**:
   - Active persona types
   - Criteria met for each persona

**Context Window Management**
- Maximum context: 8000 tokens (~6000 words)
- Priority order:
  1. Current user message
  2. Last 5 conversation messages
  3. Profile summary
  4. Top 3 recommendations
  5. Recent 20 transactions
  6. Active signals
  7. Persona information
- Truncate oldest transactions if context exceeds limit

### 5.3 Prompt Engineering

**System Prompt Structure**
```
You are a financial education assistant for MaxFinanceAI.

ROLE:
- Help users understand their spending, budgeting, and financial health
- Provide educational, supportive guidance
- Be empathetic and non-judgmental
- Use the user's actual financial data to personalize advice

CAPABILITIES:
- Answer questions about spending patterns
- Explain financial concepts in simple terms
- Help users understand their recommendations
- Compare spending across time periods
- Identify subscriptions and recurring charges
- Calculate budgets using the 50/30/20 rule

LIMITATIONS:
- DO NOT provide investment advice or stock picks
- DO NOT guarantee specific financial outcomes
- DO NOT recommend specific financial products (except in general terms)
- DO NOT provide tax or legal advice
- DO NOT encourage risky financial behavior

TONE:
- Friendly and conversational
- Educational, not preachy
- Data-driven but accessible
- Supportive and encouraging

DATA AVAILABLE:
{user_context}

When answering:
1. Reference actual data when relevant (e.g., "Your credit utilization is 45%...")
2. Explain WHY something matters (educational)
3. Provide actionable next steps
4. Keep responses concise (2-3 paragraphs max)
5. Use bullet points for lists
6. Include specific numbers from their data
```

**User Message Template**
```
Financial Context:
- Name: {name}
- Monthly Income: {income}
- Credit Utilization: {credit_util}%
- Active Personas: {personas}

Recent Transactions (Last 30 Days):
{transactions_summary}

Active Recommendations:
{recommendations}

User Question: {user_message}
```

### 5.4 Guardrails and Safety

**Content Filtering (Pre-LLM)**
- Block requests for illegal financial activities
- Block requests for specific investment advice
- Block personal attacks or abuse
- Block attempts to jailbreak/manipulate the AI
- Rate limit: 20 messages per hour per user

**Response Validation (Post-LLM)**
- Check for prohibited content:
  - Specific stock/crypto picks
  - Guaranteed returns
  - Tax/legal advice
  - Encouragement of risky behavior
- Add disclaimers when needed
- Log flagged responses for review

**Compliance Disclaimers**
Auto-append to relevant responses:
- "This is educational information only, not financial advice. Consult a licensed financial advisor for personalized recommendations."
- "Past performance doesn't guarantee future results."
- "For tax questions, please consult a licensed tax professional."

### 5.5 Performance Requirements

**Response Time**
- P50: < 1500ms
- P95: < 3000ms
- P99: < 5000ms
- Timeout: 10000ms (10s)

**Throughput**
- Support 100 concurrent chat sessions
- 1000 messages per minute across all users

**Caching Strategy**
- Cache conversation context (5 min TTL)
- Cache user profile/transaction summaries (1 min TTL)
- Cache common question responses (10 min TTL)

**Error Handling**
- LLM timeout: Fallback to "I'm having trouble processing that. Can you rephrase?"
- Rate limit: "You've reached the chat limit. Please try again in {minutes} minutes."
- API error: "I'm experiencing technical difficulties. Please try again shortly."
- Invalid input: "I don't understand. Can you ask a financial question?"

### 5.6 Security Requirements

**API Key Management**
- Store API keys in environment variables (never in code)
- Use AWS Secrets Manager or similar in production
- Rotate keys quarterly
- Separate keys for dev/staging/production

**Data Privacy**
- Never send PII to LLM logs/analytics
- Redact sensitive data before logging
- Encrypt chat history at rest
- Delete chat history after 30 days (GDPR compliance)
- User consent required before first chat

**Input Validation**
- Max message length: 500 characters
- Sanitize inputs to prevent injection attacks
- Validate user_id exists and has consent
- Block messages with suspicious patterns (SQL, code injection attempts)

---

## 6. API SPECIFICATIONS

### 6.1 POST /api/v1/chat/message

**Request**
```json
{
  "user_id": "user_abc123",
  "message": "How much did I spend on food this month?",
  "conversation_id": "conv_xyz789" // optional, creates new if not provided
}
```

**Response**
```json
{
  "conversation_id": "conv_xyz789",
  "message_id": "msg_001",
  "response": "Based on your transactions this month, you've spent $1,234 on food across 45 transactions. This breaks down to:\n\nâ€¢ Groceries: $850 (23 transactions)\nâ€¢ Dining Out: $384 (22 transactions)\n\nThis is about 15% higher than your average monthly food spending of $1,070.",
  "tokens_used": 156,
  "response_time_ms": 1250,
  "model": "claude-3-5-sonnet-20241022",
  "timestamp": "2025-11-05T10:30:00Z"
}
```

**Error Response (429 - Rate Limit)**
```json
{
  "error": "rate_limit_exceeded",
  "message": "You've sent 20 messages in the last hour. Please try again in 15 minutes.",
  "retry_after": 900 // seconds
}
```

### 6.2 POST /api/v1/chat/stream

**Request**
Same as `/message`

**Response** (Server-Sent Events)
```
data: {"type": "start", "conversation_id": "conv_xyz789", "message_id": "msg_001"}

data: {"type": "content", "delta": "Based on your"}

data: {"type": "content", "delta": " transactions this month"}

data: {"type": "content", "delta": ", you've spent $1,234"}

data: {"type": "end", "tokens_used": 156, "response_time_ms": 1250}
```

### 6.3 GET /api/v1/chat/history/{user_id}

**Query Parameters**
- `limit`: Max messages to return (default: 50, max: 100)
- `conversation_id`: Filter by conversation (optional)

**Response**
```json
{
  "user_id": "user_abc123",
  "conversations": [
    {
      "conversation_id": "conv_xyz789",
      "started_at": "2025-11-05T10:00:00Z",
      "last_message_at": "2025-11-05T10:30:00Z",
      "message_count": 6,
      "messages": [
        {
          "message_id": "msg_001",
          "role": "user",
          "content": "How much did I spend on food?",
          "timestamp": "2025-11-05T10:30:00Z"
        },
        {
          "message_id": "msg_002",
          "role": "assistant",
          "content": "Based on your transactions...",
          "timestamp": "2025-11-05T10:30:01Z"
        }
      ]
    }
  ],
  "total_conversations": 1
}
```

### 6.4 POST /api/v1/chat/feedback

**Request**
```json
{
  "message_id": "msg_002",
  "user_id": "user_abc123",
  "rating": 5, // 1-5
  "feedback_text": "Very helpful, exactly what I needed!" // optional
}
```

**Response**
```json
{
  "feedback_id": "fb_001",
  "message": "Thank you for your feedback!"
}
```

---

## 7. FRONTEND REQUIREMENTS

### 7.1 UI Changes

**FinancialChatbot.tsx Updates**
1. Replace `generatePersonalizedAdvice()` with API call to `/chat/message`
2. Add error handling for API failures
3. Add loading states with better feedback ("Analyzing your spending...")
4. Add feedback buttons (ðŸ‘/ðŸ‘Ž) on assistant messages
5. Add "New Conversation" button to reset context
6. Add typing indicator when waiting for response
7. Show token usage and response time in dev mode

**New Features**
1. **Suggested Questions**: Show 3-5 suggested questions based on user's data
   - "How much did I spend on {top_category} this month?"
   - "Show me my subscription services"
   - "Am I on track with my budget?"

2. **Response Actions**: Add action buttons to assistant responses
   - "Show transactions" â†’ Opens transaction view filtered to relevant data
   - "View recommendation" â†’ Opens recommendation detail
   - "Create budget" â†’ Opens budget creation flow

3. **Conversation Management**:
   - Save/load conversation history
   - Search through past conversations
   - Delete conversation history

### 7.2 API Integration

**Add to lib/api.ts**
```typescript
export const api = {
  // ... existing methods ...

  chat: {
    sendMessage: async (userId: string, message: string, conversationId?: string) => {
      return await fetch(`${API_BASE}/chat/message`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ user_id: userId, message, conversation_id: conversationId })
      }).then(res => res.json());
    },

    getHistory: async (userId: string, limit = 50) => {
      return await fetch(`${API_BASE}/chat/history/${userId}?limit=${limit}`)
        .then(res => res.json());
    },

    submitFeedback: async (messageId: string, userId: string, rating: number, text?: string) => {
      return await fetch(`${API_BASE}/chat/feedback`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message_id: messageId, user_id: userId, rating, feedback_text: text })
      }).then(res => res.json());
    }
  }
};
```

---

## 8. TESTING REQUIREMENTS

### 8.1 Unit Tests

**Backend Tests** (`tests/test_chat.py`)
1. Test context building with various data scenarios
2. Test prompt construction
3. Test guardrails (block prohibited content)
4. Test rate limiting
5. Test error handling (LLM timeout, invalid input)
6. Test conversation memory
7. Test token counting and truncation

**Frontend Tests**
1. Test message sending/receiving
2. Test error display
3. Test loading states
4. Test conversation history
5. Test feedback submission

### 8.2 Integration Tests

1. **End-to-End Chat Flow**
   - User sends message â†’ Receives relevant response
   - Multi-turn conversation maintains context
   - Rate limiting triggers correctly

2. **LLM Provider Switching**
   - Can switch between Claude and OpenAI
   - Fallback works if primary fails

3. **Data Accuracy**
   - Transaction queries return correct sums
   - Spending comparisons are accurate
   - Recommendations are properly referenced

### 8.3 Test Scenarios

**Scenario 1: Simple Transaction Query**
- User: "How much did I spend at Target?"
- Expected: Sum of all Target transactions with count

**Scenario 2: Category Analysis**
- User: "What's my biggest spending category?"
- Expected: Category name with total and percentage

**Scenario 3: Comparison Query**
- User: "Did I spend more on food this month vs last month?"
- Expected: Comparison with specific amounts and percentage change

**Scenario 4: Recommendation Explanation**
- User: "Why should I pay down my credit card?"
- Expected: Reference to user's credit utilization signal + recommendation rationale

**Scenario 5: Multi-Turn Conversation**
- User: "How much did I spend on dining?"
- Bot: "$384 on dining out this month"
- User: "Where did I go most often?"
- Expected: Top merchant in dining category

**Scenario 6: Guardrails Test**
- User: "What stock should I buy?"
- Expected: Polite decline + educational alternative

**Scenario 7: Rate Limit**
- Send 21 messages in 1 hour
- Expected: 21st message returns 429 error

**Scenario 8: Invalid Input**
- User: "" (empty message)
- Expected: Error message

---

## 9. IMPLEMENTATION PHASES

### Phase 1: Core Chat API (Week 1)
**Deliverables**:
- Backend `/chat/message` endpoint
- Database schema for chat_messages
- Claude API integration
- Basic context building (profile + recent transactions)
- Simple prompt template
- Frontend API integration (replace client-side logic)

**Success Criteria**:
- Can send message and receive LLM response
- Context includes user profile and 20 recent transactions
- Response time < 5s (p95)

### Phase 2: Advanced Features (Week 2)
**Deliverables**:
- Conversation memory (multi-turn)
- Enhanced context (signals, recommendations, personas)
- Guardrails implementation
- Rate limiting
- Error handling and fallbacks
- OpenAI integration as backup

**Success Criteria**:
- Multi-turn conversations work correctly
- Guardrails block prohibited content
- Rate limiting prevents abuse
- Graceful degradation on errors

### Phase 3: UX Enhancements (Week 3)
**Deliverables**:
- Streaming responses (`/chat/stream`)
- Conversation history UI
- Feedback buttons (ðŸ‘/ðŸ‘Ž)
- Suggested questions
- Response action buttons
- Loading state improvements

**Success Criteria**:
- Streaming responses feel fluid
- Users can view past conversations
- Feedback submission works
- Suggested questions are relevant

### Phase 4: Analytics & Optimization (Week 4)
**Deliverables**:
- Analytics dashboard (question types, satisfaction, errors)
- Performance optimization (caching, token reduction)
- A/B testing framework (different prompts)
- Comprehensive monitoring/alerting
- Documentation (API docs, runbook)

**Success Criteria**:
- Analytics tracking all key metrics
- Response time < 3s (p95)
- 90%+ user satisfaction
- Complete documentation

---

## 10. RISKS AND MITIGATIONS

### Risk 1: LLM Costs
**Risk**: High API costs from Claude/OpenAI
**Impact**: High
**Mitigation**:
- Implement aggressive rate limiting
- Cache common responses
- Use cheaper models for simple queries
- Monitor costs daily
- Set monthly budget alerts

### Risk 2: Poor Response Quality
**Risk**: LLM gives irrelevant or incorrect answers
**Impact**: High
**Mitigation**:
- Extensive prompt engineering and testing
- Implement response validation
- Allow users to report bad responses
- Maintain fallback to rule-based system for common questions
- Regular prompt tuning based on feedback

### Risk 3: Compliance Violations
**Risk**: LLM gives advice that violates financial regulations
**Impact**: Critical
**Mitigation**:
- Strong guardrails in system prompt
- Post-processing validation
- Legal review of disclaimers
- Log all conversations for audit
- Human review of flagged responses

### Risk 4: API Outages
**Risk**: Claude/OpenAI API goes down
**Impact**: Medium
**Mitigation**:
- Implement retry logic with exponential backoff
- Fallback to secondary provider (OpenAI â†” Claude)
- Graceful error messages to users
- Monitoring and alerts

### Risk 5: Data Privacy
**Risk**: Sensitive financial data leaked through logs
**Impact**: Critical
**Mitigation**:
- Never log full conversation content
- Redact PII before any logging
- Encrypt chat history at rest
- Regular security audits
- Clear data retention policies

### Risk 6: Rate Limit Abuse
**Risk**: Users hit rate limits frequently, poor UX
**Impact**: Medium
**Mitigation**:
- Set generous but safe limits (20/hour)
- Show remaining messages to users
- Allow rate limit increases for power users
- Queue messages instead of hard blocking

---

## 11. SUCCESS METRICS

### 11.1 Quantitative Metrics

**Engagement**
- Messages per session: Target 5+ (up from current ~2)
- Chat open rate: 60% of users use chat in first session
- Return usage: 40% of users return to chat in subsequent sessions

**Performance**
- Response time p50: < 1.5s
- Response time p95: < 3s
- Error rate: < 2%
- Uptime: 99.9%

**Quality**
- User satisfaction (thumbs up rate): > 85%
- Question comprehension: > 95% (not "I don't understand")
- Conversation length: 5+ messages per conversation

**Business**
- LLM API costs: < $0.10 per user per month
- Support ticket reduction: 30% fewer "how do I..." tickets
- Feature discovery: 50% more users discover recommendations

### 11.2 Qualitative Metrics

**User Feedback**
- Collect qualitative feedback via in-chat surveys
- NPS score for chat feature: Target > 50
- User quotes for testimonials

**A/B Testing**
- Test different prompt styles (friendly vs professional)
- Test different context levels (minimal vs comprehensive)
- Test different response lengths (concise vs detailed)

---

## 12. DEPENDENCIES

### 12.1 External Dependencies
- Anthropic Claude API access (API key required)
- OpenAI API access (backup, API key required)
- Existing database schema (Users, Transactions, Signals, Recommendations)
- Existing API endpoints (profiles, transactions, recommendations)

### 12.2 Internal Dependencies
- Backend team: API implementation
- Frontend team: UI updates
- Data team: Analytics pipeline
- Legal team: Compliance review of disclaimers
- DevOps: API key management, monitoring setup

### 12.3 Timeline Dependencies
- Phase 1 must complete before Phase 2 starts
- Legal review must complete before production launch
- Load testing must complete before public release

---

## 13. LAUNCH PLAN

### 13.1 Alpha (Internal Testing)
**Week 1-2**
- Deploy to staging environment
- Internal team testing (5-10 people)
- Fix critical bugs
- Tune prompts based on feedback

### 13.2 Beta (Limited Release)
**Week 3**
- Release to 10% of users (flag-based)
- Monitor metrics closely
- Collect feedback via surveys
- A/B test vs old rule-based system

### 13.3 General Availability
**Week 4**
- Roll out to 100% of users
- Announce feature in release notes
- Monitor for issues
- Iterate based on feedback

### 13.4 Rollback Plan
If critical issues arise:
1. Feature flag to disable LLM chat
2. Fallback to rule-based system
3. Display maintenance message
4. Fix issues in staging
5. Re-deploy when stable

---

## 14. FUTURE ENHANCEMENTS (Post-V1)

### 14.1 Voice Interface
- Speech-to-text for voice queries
- Text-to-speech for responses
- Hands-free financial assistant

### 14.2 Proactive Insights
- Daily spending summaries
- Budget alerts ("You're on track to overspend")
- Unusual transaction notifications
- Bill reminder predictions

### 14.3 Financial Planning
- Goal tracking ("Save $10k for vacation")
- Debt payoff calculators
- Retirement planning
- What-if scenarios

### 14.4 Multi-Modal Responses
- Charts and graphs in chat
- Spend visualizations
- Budget progress bars
- Interactive widgets

### 14.5 Advanced Search
- "Show all transactions over $100 last month"
- "Find duplicate subscriptions"
- "What's my average grocery bill?"
- Natural language SQL generation

---

## 15. APPENDIX

### 15.1 Sample Conversations

**Example 1: Transaction Search**
```
User: How much did I spend on coffee last week?
Bot: Last week you spent $42.50 on coffee across 5 transactions:
â€¢ Starbucks (3 times): $28.75
â€¢ Blue Bottle (1 time): $8.50
â€¢ Peet's Coffee (1 time): $5.25

That's about $8.50 per day on weekdays. At this rate, you'll spend about $170/month on coffee. Would you like tips on reducing this expense?
```

**Example 2: Budget Advice**
```
User: Help me create a budget
Bot: Based on your average monthly income of $5,200, here's a recommended budget using the 50/30/20 rule:

NEEDS (50% = $2,600):
â€¢ Rent/Housing: $1,500
â€¢ Utilities: $150
â€¢ Groceries: $400
â€¢ Transportation: $300
â€¢ Insurance: $250

WANTS (30% = $1,560):
â€¢ Dining out: $400
â€¢ Entertainment: $200
â€¢ Shopping: $500
â€¢ Subscriptions: $100
â€¢ Other: $360

SAVINGS (20% = $1,040):
â€¢ Emergency fund: $520
â€¢ Retirement: $520

Looking at your actual spending from last month, you're currently spending $2,100 on Wants (40%). Would you like suggestions on where to cut back?
```

**Example 3: Recommendation Explanation**
```
User: Why are you telling me to pay down my credit card?
Bot: Great question! I'm recommending this for a few specific reasons based on your data:

1. HIGH UTILIZATION: Your credit card balance is $4,500 out of a $5,000 limit (90% utilization). Credit bureaus recommend keeping this under 30%.

2. IMPACT ON CREDIT SCORE: High utilization can lower your score by 50-100 points, making it harder to get good rates on loans.

3. INTEREST COSTS: At 22.99% APR, you're paying about $86/month in interest. That's $1,032 per year!

SUGGESTED ACTION: Pay $2,000 to get under 50% utilization. This will:
â€¢ Save ~$38/month in interest
â€¢ Likely improve your credit score
â€¢ Make you eligible for better credit cards

Want me to help you figure out where to find that $2,000?
```

### 15.2 Technical Configuration

**Environment Variables**
```
# LLM Configuration
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
LLM_PROVIDER=anthropic # or 'openai'
LLM_MODEL=claude-3-5-sonnet-20241022
LLM_MAX_TOKENS=1024
LLM_TEMPERATURE=0.7
LLM_TIMEOUT=10000 # milliseconds

# Rate Limiting
CHAT_RATE_LIMIT_MESSAGES=20
CHAT_RATE_LIMIT_WINDOW=3600 # seconds (1 hour)

# Context Management
CHAT_MAX_CONTEXT_TOKENS=8000
CHAT_CONVERSATION_HISTORY_LENGTH=5
CHAT_MAX_TRANSACTIONS=20

# Caching
CHAT_CONTEXT_CACHE_TTL=300 # 5 minutes
CHAT_RESPONSE_CACHE_TTL=600 # 10 minutes

# Security
CHAT_MAX_MESSAGE_LENGTH=500
CHAT_HISTORY_RETENTION_DAYS=30
```

**Database Migrations**
```sql
-- Create chat_messages table
CREATE TABLE chat_messages (
    message_id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL REFERENCES users(user_id),
    conversation_id UUID NOT NULL,
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,
    tokens_used INTEGER,
    response_time_ms INTEGER,
    model_used VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_user_conversation (user_id, conversation_id),
    INDEX idx_created_at (created_at)
);

-- Create chat_feedback table
CREATE TABLE chat_feedback (
    feedback_id SERIAL PRIMARY KEY,
    message_id INTEGER NOT NULL REFERENCES chat_messages(message_id),
    user_id VARCHAR(50) NOT NULL REFERENCES users(user_id),
    rating INTEGER NOT NULL CHECK (rating BETWEEN 1 AND 5),
    feedback_text TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_message (message_id),
    INDEX idx_rating (rating)
);

-- Add indexes for performance
CREATE INDEX idx_chat_user_recent ON chat_messages(user_id, created_at DESC);
CREATE INDEX idx_chat_conversation ON chat_messages(conversation_id, created_at ASC);
```

### 15.3 Monitoring and Alerts

**Key Metrics to Monitor**
1. Chat API response time (p50, p95, p99)
2. LLM API error rate
3. Rate limit hit rate
4. Token usage per request
5. User satisfaction (thumbs up/down ratio)
6. Conversation length distribution
7. Daily active chat users
8. LLM API costs

**Alert Thresholds**
- Response time p95 > 5s â†’ Warning
- Error rate > 5% â†’ Critical
- API costs > $500/day â†’ Warning
- Satisfaction < 70% â†’ Warning

---

## 16. SIGN-OFF

This PRD requires approval from:
- [ ] Product Manager
- [ ] Engineering Lead
- [ ] Design Lead
- [ ] Legal/Compliance
- [ ] Finance (budget approval)

Document Version: 1.0
Last Updated: 2025-11-05
Author: AI Product Team
