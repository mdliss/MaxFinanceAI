# Task Breakdown: AI-Powered Financial Chatbot Upgrade

## LEGEND
Priority: [P0 = Critical, P1 = High, P2 = Medium, P3 = Low]
Effort: [XS = 1-2hrs, S = 2-4hrs, M = 4-8hrs, L = 1-2 days, XL = 2-5 days]
Dependencies: Task IDs that must complete first

---

# PHASE 1: CORE CHAT API (WEEK 1)

## 1. Database Schema & Migrations

### TASK-1.1: Create chat_messages table
**Priority**: P0
**Effort**: S (3 hours)
**Dependencies**: None
**Description**:
Create database schema for storing chat messages with proper indexing for performance.

**Acceptance Criteria**:
- [ ] Table created with columns: message_id, user_id, conversation_id, role, content, tokens_used, response_time_ms, model_used, created_at
- [ ] Indexes created on: (user_id, conversation_id), (created_at), (user_id, created_at DESC), (conversation_id, created_at ASC)
- [ ] Foreign key constraint to users table
- [ ] Role check constraint (user/assistant/system)
- [ ] Migration script tested in dev environment
- [ ] Rollback script created and tested

**Files to Create/Modify**:
- `backend/alembic/versions/XXX_create_chat_tables.py` (new)

**Testing**:
- Run migration up and down
- Verify indexes exist
- Test foreign key constraint
- Insert sample data and query performance

---

### TASK-1.2: Create chat_feedback table
**Priority**: P1
**Effort**: S (2 hours)
**Dependencies**: TASK-1.1
**Description**:
Create table for storing user feedback on chat responses (thumbs up/down).

**Acceptance Criteria**:
- [ ] Table created with columns: feedback_id, message_id, user_id, rating, feedback_text, created_at
- [ ] Foreign key to chat_messages and users tables
- [ ] Rating check constraint (1-5)
- [ ] Indexes on message_id and rating
- [ ] Migration tested

**Files to Create/Modify**:
- `backend/alembic/versions/XXX_create_chat_tables.py` (update)

---

### TASK-1.3: Create SQLAlchemy models
**Priority**: P0
**Effort**: S (2 hours)
**Dependencies**: TASK-1.1, TASK-1.2
**Description**:
Create ORM models for chat_messages and chat_feedback tables.

**Acceptance Criteria**:
- [ ] ChatMessage model with all fields and relationships
- [ ] ChatFeedback model with all fields and relationships
- [ ] Proper type hints
- [ ] Relationship to User model
- [ ] Model serialization methods (to_dict)
- [ ] Docstrings for all models

**Files to Create/Modify**:
- `backend/app/models/chat.py` (new)
- `backend/app/models/__init__.py` (update imports)

**Code Snippet**:
```python
from sqlalchemy import Column, Integer, String, Text, ForeignKey, DateTime, CheckConstraint
from sqlalchemy.orm import relationship
from datetime import datetime
from .base import Base

class ChatMessage(Base):
    __tablename__ = "chat_messages"

    message_id = Column(Integer, primary_key=True)
    user_id = Column(String(50), ForeignKey("users.user_id"), nullable=False)
    conversation_id = Column(String(36), nullable=False)  # UUID
    role = Column(String(20), nullable=False)
    content = Column(Text, nullable=False)
    tokens_used = Column(Integer)
    response_time_ms = Column(Integer)
    model_used = Column(String(100))
    created_at = Column(DateTime, default=datetime.utcnow)

    # Relationships
    user = relationship("User", back_populates="chat_messages")
    feedback = relationship("ChatFeedback", back_populates="message", uselist=False)

    __table_args__ = (
        CheckConstraint(role.in_(['user', 'assistant', 'system']), name='valid_role'),
    )
```

---

## 2. LLM Integration Layer

### TASK-2.1: Set up Anthropic Claude SDK
**Priority**: P0
**Effort**: XS (1 hour)
**Dependencies**: None
**Description**:
Install and configure Anthropic SDK for Claude API integration.

**Acceptance Criteria**:
- [ ] anthropic package added to requirements.txt
- [ ] Environment variable ANTHROPIC_API_KEY configured
- [ ] Test script to verify API connection works
- [ ] Error handling for missing/invalid API key
- [ ] .env.example updated with placeholder

**Files to Create/Modify**:
- `backend/requirements.txt` (add anthropic>=0.8.0)
- `backend/.env.example` (add ANTHROPIC_API_KEY=sk-ant-...)
- `backend/tests/test_claude_connection.py` (new)

---

### TASK-2.2: Create LLM service abstraction
**Priority**: P0
**Effort**: M (5 hours)
**Dependencies**: TASK-2.1
**Description**:
Create a service layer that abstracts LLM provider (Claude/OpenAI) with common interface.

**Acceptance Criteria**:
- [ ] BaseLLMService abstract class with send_message() method
- [ ] ClaudeService implementation
- [ ] OpenAIService stub (for future Phase 2)
- [ ] Factory pattern to select provider via config
- [ ] Retry logic with exponential backoff (max 3 retries)
- [ ] Timeout handling (10s default)
- [ ] Token counting utility
- [ ] Comprehensive error handling

**Files to Create/Modify**:
- `backend/app/services/llm/__init__.py` (new)
- `backend/app/services/llm/base.py` (new)
- `backend/app/services/llm/claude.py` (new)
- `backend/app/services/llm/openai.py` (new stub)
- `backend/app/services/llm/factory.py` (new)

**Code Snippet**:
```python
# base.py
from abc import ABC, abstractmethod
from typing import Dict, List

class BaseLLMService(ABC):
    @abstractmethod
    async def send_message(
        self,
        system_prompt: str,
        user_message: str,
        conversation_history: List[Dict],
        max_tokens: int = 1024,
        temperature: float = 0.7
    ) -> Dict:
        """Send message to LLM and get response.

        Returns:
            {
                "content": str,
                "tokens_used": int,
                "model": str,
                "response_time_ms": int
            }
        """
        pass

# claude.py
import time
from anthropic import Anthropic, APIError, APITimeoutError
from .base import BaseLLMService

class ClaudeService(BaseLLMService):
    def __init__(self, api_key: str):
        self.client = Anthropic(api_key=api_key)

    async def send_message(self, system_prompt, user_message, conversation_history, max_tokens=1024, temperature=0.7):
        start_time = time.time()

        # Build messages array
        messages = []
        for msg in conversation_history:
            messages.append({"role": msg["role"], "content": msg["content"]})
        messages.append({"role": "user", "content": user_message})

        # Call Claude with retries
        for attempt in range(3):
            try:
                response = self.client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=max_tokens,
                    temperature=temperature,
                    system=system_prompt,
                    messages=messages
                )

                return {
                    "content": response.content[0].text,
                    "tokens_used": response.usage.input_tokens + response.usage.output_tokens,
                    "model": response.model,
                    "response_time_ms": int((time.time() - start_time) * 1000)
                }
            except APITimeoutError:
                if attempt == 2:
                    raise
                await asyncio.sleep(2 ** attempt)
            except APIError as e:
                # Handle rate limits, invalid requests, etc.
                raise
```

---

### TASK-2.3: Create context builder service
**Priority**: P0
**Effort**: L (8 hours)
**Dependencies**: None
**Description**:
Build service that gathers user's financial data and formats it for LLM context.

**Acceptance Criteria**:
- [ ] Fetches user profile (name, income, age)
- [ ] Fetches recent 20 transactions with category grouping
- [ ] Fetches active signals (credit_utilization, spending_surge, etc.)
- [ ] Fetches approved recommendations
- [ ] Fetches active personas
- [ ] Calculates spending by category (last 30 days)
- [ ] Formats everything into concise text summary
- [ ] Token counting to ensure context < 8000 tokens
- [ ] Truncates oldest data if exceeds limit
- [ ] Caching with 1-min TTL (Redis or in-memory)

**Files to Create/Modify**:
- `backend/app/services/chat/context_builder.py` (new)
- `backend/app/services/chat/__init__.py` (new)

**Code Snippet**:
```python
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from app.models import User, Transaction, Signal, Recommendation, Persona
from datetime import datetime, timedelta
from typing import Dict
import tiktoken  # for token counting

class ContextBuilder:
    def __init__(self, db: AsyncSession):
        self.db = db
        self.encoder = tiktoken.encoding_for_model("gpt-4")  # Similar to Claude

    async def build_context(self, user_id: str, max_tokens: int = 6000) -> str:
        """Build financial context for user."""
        # Fetch all data in parallel
        profile = await self._get_profile(user_id)
        transactions = await self._get_recent_transactions(user_id, limit=20)
        signals = await self._get_signals(user_id)
        recommendations = await self._get_recommendations(user_id)
        personas = await self._get_personas(user_id)
        spending_summary = await self._get_spending_summary(user_id)

        # Build context sections
        context_parts = [
            self._format_profile(profile),
            self._format_spending_summary(spending_summary),
            self._format_signals(signals),
            self._format_recommendations(recommendations),
            self._format_transactions(transactions),
            self._format_personas(personas)
        ]

        # Join and check token count
        context = "\n\n".join(context_parts)
        tokens = len(self.encoder.encode(context))

        # Truncate if needed (remove oldest transactions first)
        while tokens > max_tokens and len(transactions) > 5:
            transactions = transactions[:-5]
            context_parts[4] = self._format_transactions(transactions)
            context = "\n\n".join(context_parts)
            tokens = len(self.encoder.encode(context))

        return context

    async def _get_profile(self, user_id: str) -> Dict:
        result = await self.db.execute(
            select(User).where(User.user_id == user_id)
        )
        user = result.scalar_one_or_none()
        return {
            "name": user.name,
            "age": user.age,
            "income_level": user.income_level
        } if user else {}

    async def _get_recent_transactions(self, user_id: str, limit: int = 20):
        cutoff = datetime.now() - timedelta(days=30)
        result = await self.db.execute(
            select(Transaction)
            .where(Transaction.user_id == user_id)
            .where(Transaction.transaction_date >= cutoff)
            .order_by(Transaction.transaction_date.desc())
            .limit(limit)
        )
        return result.scalars().all()

    def _format_profile(self, profile: Dict) -> str:
        return f"""USER PROFILE:
- Name: {profile.get('name', 'Unknown')}
- Age: {profile.get('age', 'N/A')}
- Income Level: {profile.get('income_level', 'N/A')}"""

    # ... other formatting methods
```

---

### TASK-2.4: Create prompt templates
**Priority**: P0
**Effort**: M (4 hours)
**Dependencies**: None
**Description**:
Design and implement system prompts and message templates for financial chatbot.

**Acceptance Criteria**:
- [ ] System prompt with role definition, capabilities, limitations, tone guidance
- [ ] User message template that injects context
- [ ] Separate prompts for different use cases (transaction search, budget advice, general Q&A)
- [ ] Prompt versioning system (v1, v2, etc.)
- [ ] Configuration to A/B test different prompts
- [ ] Documentation of prompt engineering principles used
- [ ] Examples of good/bad prompts tested

**Files to Create/Modify**:
- `backend/app/services/chat/prompts.py` (new)

**Code Snippet**:
```python
SYSTEM_PROMPT_V1 = """You are a financial education assistant for MaxFinanceAI.

ROLE:
- Help users understand their spending, budgeting, and financial health
- Provide educational, supportive guidance based on their actual financial data
- Be empathetic and non-judgmental
- Empower users to make informed decisions

CAPABILITIES:
- Answer questions about spending patterns using actual transaction data
- Explain financial concepts in simple, accessible language
- Help users understand their personalized recommendations
- Compare spending across time periods
- Identify subscriptions and recurring charges
- Calculate budgets using evidence-based methods (50/30/20 rule)
- Provide actionable next steps

STRICT LIMITATIONS (NEVER violate these):
- DO NOT provide specific investment advice or stock picks
- DO NOT guarantee specific financial outcomes
- DO NOT recommend specific financial products by name (except in general educational terms)
- DO NOT provide tax or legal advice - always refer to licensed professionals
- DO NOT encourage risky financial behavior (gambling, day trading, high-interest debt)
- DO NOT make the user feel bad about past decisions

TONE & STYLE:
- Friendly and conversational, like talking to a knowledgeable friend
- Educational without being preachy or condescending
- Data-driven but accessible (avoid jargon)
- Supportive and encouraging
- Concise - keep responses to 2-3 paragraphs max
- Use bullet points for clarity
- Include specific numbers from their data when relevant

RESPONSE FORMAT:
1. Directly answer the question using their actual data
2. Explain WHY it matters (educational component)
3. Provide 1-2 actionable next steps
4. If relevant, reference one of their personalized recommendations

EXAMPLES:

User: "How much did I spend on food this month?"
Good Response:
"Based on your transactions, you've spent $1,234 on food this month across 45 transactions:
â€¢ Groceries: $850 (23 transactions)
â€¢ Dining Out: $384 (22 transactions)

This is about 15% higher than your typical monthly food spending of $1,070. The increase is mainly from dining out ($384 vs your usual $280).

ðŸ’¡ Quick tip: If you reduced dining out by just 2 meals/week, you'd save about $120/month ($1,440/year). Want to set a dining budget?"

Bad Response (too vague):
"You spent a lot on food. Try to eat at home more."

When you don't know something or don't have data:
- Be honest: "I don't have enough transaction history to answer that yet."
- Offer alternative: "Once you have 2-3 months of data, I can show trends."
- Provide general guidance: "In general, financial experts recommend..."

Remember: Your goal is EDUCATION and EMPOWERMENT, not judgment or prescription."""

def build_user_message(context: str, question: str) -> str:
    return f"""FINANCIAL CONTEXT:
{context}

USER QUESTION: {question}

Provide a helpful, data-driven response using the context above. Reference specific numbers when relevant."""
```

---

## 3. Chat API Endpoints

### TASK-3.1: Create POST /chat/message endpoint
**Priority**: P0
**Effort**: L (8 hours)
**Dependencies**: TASK-1.3, TASK-2.2, TASK-2.3, TASK-2.4
**Description**:
Implement main chat endpoint that processes user messages and returns LLM responses.

**Acceptance Criteria**:
- [ ] Validates user_id exists and has consent
- [ ] Validates message is not empty and < 500 chars
- [ ] Generates or uses existing conversation_id
- [ ] Builds financial context using ContextBuilder
- [ ] Sends message to LLM service
- [ ] Saves both user and assistant messages to database
- [ ] Returns response with metadata (tokens, response time, model)
- [ ] Handles errors gracefully (timeout, API error, invalid input)
- [ ] Returns proper HTTP status codes (200, 400, 429, 500)
- [ ] Logs request/response for monitoring
- [ ] Response time < 5s (p95)

**Files to Create/Modify**:
- `backend/app/api/chat.py` (new)
- `backend/app/api/__init__.py` (update to include chat router)
- `backend/app/main.py` (register chat router)

**Code Snippet**:
```python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from typing import Optional
import uuid
from datetime import datetime

from app.database import get_db
from app.models import User, ChatMessage
from app.services.llm.factory import get_llm_service
from app.services.chat.context_builder import ContextBuilder
from app.services.chat.prompts import SYSTEM_PROMPT_V1, build_user_message

router = APIRouter(prefix="/chat", tags=["chat"])

class ChatRequest(BaseModel):
    user_id: str
    message: str = Field(..., min_length=1, max_length=500)
    conversation_id: Optional[str] = None

class ChatResponse(BaseModel):
    conversation_id: str
    message_id: int
    response: str
    tokens_used: int
    response_time_ms: int
    model: str
    timestamp: str

@router.post("/message", response_model=ChatResponse)
async def send_message(
    request: ChatRequest,
    db: AsyncSession = Depends(get_db)
):
    """Send a message and get AI response."""

    # 1. Validate user exists and has consent
    result = await db.execute(
        select(User).where(User.user_id == request.user_id)
    )
    user = result.scalar_one_or_none()

    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="User not found"
        )

    if not user.consent_status:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="User has not provided consent for AI features"
        )

    # 2. Generate or use existing conversation_id
    conversation_id = request.conversation_id or str(uuid.uuid4())

    # 3. Save user message to database
    user_message = ChatMessage(
        user_id=request.user_id,
        conversation_id=conversation_id,
        role="user",
        content=request.message,
        created_at=datetime.utcnow()
    )
    db.add(user_message)
    await db.commit()
    await db.refresh(user_message)

    try:
        # 4. Build context
        context_builder = ContextBuilder(db)
        context = await context_builder.build_context(request.user_id)

        # 5. Get conversation history (last 5 messages)
        history_result = await db.execute(
            select(ChatMessage)
            .where(ChatMessage.conversation_id == conversation_id)
            .where(ChatMessage.message_id != user_message.message_id)
            .order_by(ChatMessage.created_at.desc())
            .limit(5)
        )
        history = history_result.scalars().all()
        history_formatted = [
            {"role": msg.role, "content": msg.content}
            for msg in reversed(history)
        ]

        # 6. Get LLM response
        llm = get_llm_service()
        user_message_formatted = build_user_message(context, request.message)

        llm_response = await llm.send_message(
            system_prompt=SYSTEM_PROMPT_V1,
            user_message=user_message_formatted,
            conversation_history=history_formatted,
            max_tokens=1024,
            temperature=0.7
        )

        # 7. Save assistant response to database
        assistant_message = ChatMessage(
            user_id=request.user_id,
            conversation_id=conversation_id,
            role="assistant",
            content=llm_response["content"],
            tokens_used=llm_response["tokens_used"],
            response_time_ms=llm_response["response_time_ms"],
            model_used=llm_response["model"],
            created_at=datetime.utcnow()
        )
        db.add(assistant_message)
        await db.commit()
        await db.refresh(assistant_message)

        # 8. Return response
        return ChatResponse(
            conversation_id=conversation_id,
            message_id=assistant_message.message_id,
            response=llm_response["content"],
            tokens_used=llm_response["tokens_used"],
            response_time_ms=llm_response["response_time_ms"],
            model=llm_response["model"],
            timestamp=assistant_message.created_at.isoformat()
        )

    except Exception as e:
        # Log error and return generic error message
        print(f"Chat error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="I'm experiencing technical difficulties. Please try again shortly."
        )
```

**Testing**:
- Unit test with mocked LLM service
- Integration test with real Claude API (dev key)
- Test error scenarios (invalid user, no consent, timeout, API error)
- Load test with 50 concurrent requests

---

### TASK-3.2: Create GET /chat/history endpoint
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-1.3
**Description**:
Endpoint to retrieve conversation history for a user.

**Acceptance Criteria**:
- [ ] Returns all conversations for a user
- [ ] Supports pagination (limit, offset)
- [ ] Can filter by conversation_id
- [ ] Orders by timestamp (newest first)
- [ ] Includes message count per conversation
- [ ] Groups messages by conversation
- [ ] Returns 404 if user not found
- [ ] Respects data privacy (only returns data for authenticated user)

**Files to Create/Modify**:
- `backend/app/api/chat.py` (update)

---

### TASK-3.3: Create DELETE /chat/history endpoint
**Priority**: P2
**Effort**: XS (2 hours)
**Dependencies**: TASK-1.3
**Description**:
Endpoint to clear conversation history for a user (GDPR compliance).

**Acceptance Criteria**:
- [ ] Deletes all messages for a user
- [ ] Can delete specific conversation_id
- [ ] Returns count of deleted messages
- [ ] Soft delete vs hard delete (configurable)
- [ ] Audit log entry for deletion
- [ ] Requires user confirmation (pass confirm=true param)

**Files to Create/Modify**:
- `backend/app/api/chat.py` (update)

---

### TASK-3.4: Create POST /chat/feedback endpoint
**Priority**: P1
**Effort**: S (2 hours)
**Dependencies**: TASK-1.3
**Description**:
Endpoint for users to rate chat responses (thumbs up/down).

**Acceptance Criteria**:
- [ ] Validates message_id exists
- [ ] Validates rating is 1-5
- [ ] Stores feedback with optional text comment
- [ ] Prevents duplicate feedback (1 per message per user)
- [ ] Returns feedback_id
- [ ] Updates analytics

**Files to Create/Modify**:
- `backend/app/api/chat.py` (update)

---

## 4. Frontend Integration

### TASK-4.1: Add chat API methods to lib/api.ts
**Priority**: P0
**Effort**: XS (1 hour)
**Dependencies**: TASK-3.1
**Description**:
Add TypeScript API client methods for chat endpoints.

**Acceptance Criteria**:
- [ ] sendMessage(userId, message, conversationId?) method
- [ ] getHistory(userId, limit, conversationId?) method
- [ ] submitFeedback(messageId, userId, rating, text?) method
- [ ] clearHistory(userId, conversationId?) method
- [ ] Proper error handling
- [ ] TypeScript types for request/response

**Files to Create/Modify**:
- `frontend/src/lib/api.ts` (update)
- `frontend/src/types/chat.ts` (new)

**Code Snippet**:
```typescript
// types/chat.ts
export interface ChatMessage {
  message_id: number;
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: string;
}

export interface ChatResponse {
  conversation_id: string;
  message_id: number;
  response: string;
  tokens_used: number;
  response_time_ms: number;
  model: string;
  timestamp: string;
}

// lib/api.ts
export const api = {
  // ... existing methods ...

  chat: {
    sendMessage: async (
      userId: string,
      message: string,
      conversationId?: string
    ): Promise<ChatResponse> => {
      const response = await fetch(`${API_BASE}/chat/message`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          user_id: userId,
          message,
          conversation_id: conversationId
        })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.detail || 'Failed to send message');
      }

      return response.json();
    },

    getHistory: async (userId: string, limit = 50, conversationId?: string) => {
      const params = new URLSearchParams({ limit: limit.toString() });
      if (conversationId) params.append('conversation_id', conversationId);

      const response = await fetch(
        `${API_BASE}/chat/history/${userId}?${params}`
      );
      return response.json();
    },

    submitFeedback: async (
      messageId: number,
      userId: string,
      rating: number,
      feedbackText?: string
    ) => {
      return fetch(`${API_BASE}/chat/feedback`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message_id: messageId,
          user_id: userId,
          rating,
          feedback_text: feedbackText
        })
      }).then(res => res.json());
    }
  }
};
```

---

### TASK-4.2: Update FinancialChatbot.tsx to use API
**Priority**: P0
**Effort**: M (6 hours)
**Dependencies**: TASK-4.1
**Description**:
Replace client-side generatePersonalizedAdvice() logic with API calls.

**Acceptance Criteria**:
- [ ] Remove old generatePersonalizedAdvice() function (lines 62-202)
- [ ] Update handleSend() to call api.chat.sendMessage()
- [ ] Store conversation_id in component state
- [ ] Handle loading state properly
- [ ] Display error messages from API
- [ ] Show response time in dev mode
- [ ] Handle network errors gracefully
- [ ] Retry failed requests (1 retry)
- [ ] Update quick questions to work with new system
- [ ] Preserve existing UI/UX (floating button, animations, etc.)

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (major update)

**Code Snippet**:
```typescript
// Update handleSend function
const handleSend = async () => {
  if (!input.trim()) return;

  const userMessage: Message = {
    id: Date.now().toString(),
    role: 'user',
    content: input,
    timestamp: new Date(),
  };

  setMessages(prev => [...prev, userMessage]);
  setInput('');
  setLoading(true);

  try {
    const response = await api.chat.sendMessage(
      userId,
      input,
      conversationId
    );

    // Store conversation_id for future messages
    if (!conversationId) {
      setConversationId(response.conversation_id);
    }

    const assistantMessage: Message = {
      id: response.message_id.toString(),
      role: 'assistant',
      content: response.response,
      timestamp: new Date(response.timestamp),
    };

    setMessages(prev => [...prev, assistantMessage]);

    // Show response time in dev mode
    if (process.env.NODE_ENV === 'development') {
      console.log(`Response time: ${response.response_time_ms}ms, Tokens: ${response.tokens_used}`);
    }
  } catch (error) {
    console.error('Failed to send message:', error);

    const errorMessage: Message = {
      id: (Date.now() + 1).toString(),
      role: 'assistant',
      content: "I'm having trouble processing your request. Please try again in a moment.",
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, errorMessage]);
  } finally {
    setLoading(false);
    if (!isOpen) {
      setUnreadCount(c => c + 1);
    }
  }
};
```

---

### TASK-4.3: Add feedback buttons to chat messages
**Priority**: P2
**Effort**: S (3 hours)
**Dependencies**: TASK-4.2
**Description**:
Add thumbs up/down buttons to assistant messages for feedback collection.

**Acceptance Criteria**:
- [ ] Show ðŸ‘/ðŸ‘Ž buttons on assistant messages
- [ ] Only show on messages that haven't been rated
- [ ] Call api.chat.submitFeedback() on click
- [ ] Show confirmation ("Thanks for feedback!")
- [ ] Disable buttons after rating
- [ ] Optional: Show feedback form for thumbs down
- [ ] Track feedback in analytics

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (update)

---

### TASK-4.4: Update loading states
**Priority**: P2
**Effort**: XS (2 hours)
**Dependencies**: TASK-4.2
**Description**:
Improve loading UX with contextual messages.

**Acceptance Criteria**:
- [ ] Show different loading messages based on question type
  - "Analyzing your spending..." for spending questions
  - "Calculating your budget..." for budget questions
  - "Searching transactions..." for transaction queries
  - "Thinking..." for general questions
- [ ] Estimate time remaining (if response > 2s)
- [ ] Cancel button (abort request)

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (update)

---

## 5. Testing & Quality Assurance

### TASK-5.1: Write unit tests for context builder
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-2.3
**Description**:
Comprehensive unit tests for ContextBuilder service.

**Acceptance Criteria**:
- [ ] Test with various data scenarios (no transactions, lots of transactions, etc.)
- [ ] Test token counting and truncation
- [ ] Test caching behavior
- [ ] Test error handling (missing data)
- [ ] Test formatting methods
- [ ] 90%+ code coverage

**Files to Create/Modify**:
- `backend/tests/services/test_context_builder.py` (new)

---

### TASK-5.2: Write unit tests for LLM service
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-2.2
**Description**:
Unit tests for LLM service with mocked API calls.

**Acceptance Criteria**:
- [ ] Test successful response
- [ ] Test timeout handling
- [ ] Test retry logic
- [ ] Test error handling (API errors, rate limits)
- [ ] Test token counting
- [ ] Mock Anthropic API calls

**Files to Create/Modify**:
- `backend/tests/services/test_llm_service.py` (new)

---

### TASK-5.3: Write integration tests for chat endpoint
**Priority**: P1
**Effort**: L (6 hours)
**Dependencies**: TASK-3.1
**Description**:
End-to-end tests for chat API with real database and mocked LLM.

**Acceptance Criteria**:
- [ ] Test successful message send
- [ ] Test conversation continuity (multi-turn)
- [ ] Test error scenarios (invalid user, no consent, etc.)
- [ ] Test rate limiting
- [ ] Test concurrent requests
- [ ] Use pytest fixtures for test data
- [ ] Clean up test data after each test

**Files to Create/Modify**:
- `backend/tests/api/test_chat.py` (new)

---

### TASK-5.4: Manual testing with real users
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-4.2
**Description**:
Manual QA testing with sample questions and edge cases.

**Test Scenarios**:
1. Simple transaction query: "How much did I spend at Target?"
2. Category analysis: "What's my biggest spending category?"
3. Comparison: "Am I spending more this month vs last month?"
4. Recommendation question: "Why should I pay down my credit card?"
5. Multi-turn: Ask follow-up questions
6. Invalid input: Empty message, very long message
7. Edge cases: New user with no transactions, user without consent

**Acceptance Criteria**:
- [ ] All scenarios documented with screenshots
- [ ] Response quality rated (1-5)
- [ ] Any issues logged in bug tracker
- [ ] Response times recorded

**Deliverables**:
- QA test report document
- Bug list (if any)

---

### TASK-5.5: Performance testing
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-3.1
**Description**:
Load test chat API to ensure it meets performance requirements.

**Acceptance Criteria**:
- [ ] Test with 50 concurrent users
- [ ] Measure p50, p95, p99 response times
- [ ] Test sustained load (100 req/min for 10 minutes)
- [ ] Identify bottlenecks
- [ ] Document results
- [ ] Meet targets: p95 < 5s

**Tools**:
- Use locust or artillery for load testing
- Monitor database query performance
- Monitor LLM API response times

**Files to Create/Modify**:
- `backend/tests/load/test_chat_performance.py` (new)

---

## 6. Documentation

### TASK-6.1: Write API documentation
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-3.1, TASK-3.2, TASK-3.3, TASK-3.4
**Description**:
Comprehensive API docs for chat endpoints.

**Acceptance Criteria**:
- [ ] OpenAPI/Swagger spec for all endpoints
- [ ] Request/response examples
- [ ] Error response documentation
- [ ] Rate limiting documentation
- [ ] Authentication/authorization requirements
- [ ] Code examples in Python and TypeScript

**Files to Create/Modify**:
- `backend/docs/api/chat.md` (new)
- Update FastAPI schema with descriptions

---

### TASK-6.2: Write deployment guide
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: All Phase 1 tasks
**Description**:
Step-by-step guide for deploying chat feature to production.

**Acceptance Criteria**:
- [ ] Environment variable setup
- [ ] Database migration steps
- [ ] API key configuration (Anthropic)
- [ ] Monitoring setup
- [ ] Rollback procedures
- [ ] Health check endpoints
- [ ] Troubleshooting guide

**Files to Create/Modify**:
- `backend/docs/deployment/chat_deployment.md` (new)

---

### TASK-6.3: Update user-facing documentation
**Priority**: P2
**Effort**: S (2 hours)
**Dependencies**: TASK-4.2
**Description**:
User guide for the new chat feature.

**Acceptance Criteria**:
- [ ] What questions can the chatbot answer?
- [ ] How to get the best results
- [ ] Privacy and data usage
- [ ] Example questions
- [ ] FAQ
- [ ] Screenshots

**Files to Create/Modify**:
- `docs/user_guide/chatbot.md` (new)

---

# PHASE 2: ADVANCED FEATURES (WEEK 2)

## 7. Conversation Memory

### TASK-7.1: Implement conversation context management
**Priority**: P0
**Effort**: M (5 hours)
**Dependencies**: TASK-3.1
**Description**:
Improve multi-turn conversations by maintaining richer context.

**Acceptance Criteria**:
- [ ] Load last 10 messages (up from 5) for context
- [ ] Summarize older messages if context exceeds token limit
- [ ] Detect topic changes and start new conversation
- [ ] Store conversation metadata (topic, start_time, message_count)
- [ ] Implement conversation summarization (for very long conversations)

**Files to Create/Modify**:
- `backend/app/services/chat/conversation_manager.py` (new)
- `backend/app/api/chat.py` (update to use ConversationManager)

---

### TASK-7.2: Add conversation topic detection
**Priority**: P2
**Effort**: M (4 hours)
**Dependencies**: TASK-7.1
**Description**:
Automatically detect conversation topics for better organization.

**Acceptance Criteria**:
- [ ] Use LLM to summarize conversation topic
- [ ] Store topic in conversation metadata
- [ ] Display topic in conversation history UI
- [ ] Group conversations by topic

**Files to Create/Modify**:
- `backend/app/services/chat/topic_detector.py` (new)

---

## 8. Enhanced Context & Intelligence

### TASK-8.1: Add transaction search capability
**Priority**: P0
**Effort**: L (8 hours)
**Dependencies**: TASK-2.3
**Description**:
Enable natural language transaction search (e.g., "How much did I spend at Starbucks last week?").

**Acceptance Criteria**:
- [ ] Parse natural language queries into SQL filters
- [ ] Support merchant search
- [ ] Support category search
- [ ] Support date range search ("last week", "this month", "Q1")
- [ ] Support amount filters (">$100", "under $50")
- [ ] Return transaction summaries with totals
- [ ] Handle fuzzy matching for merchant names

**Files to Create/Modify**:
- `backend/app/services/chat/transaction_search.py` (new)
- Update context builder to include transaction search results

**Code Snippet**:
```python
class TransactionSearchService:
    def __init__(self, db: AsyncSession):
        self.db = db

    async def search(self, user_id: str, query: str) -> Dict:
        """Parse natural language query and search transactions."""
        # Use LLM to extract filters from query
        filters = await self._parse_query(query)

        # Build SQL query
        q = select(Transaction).where(Transaction.user_id == user_id)

        if filters.get('merchant'):
            q = q.where(Transaction.merchant_name.ilike(f"%{filters['merchant']}%"))

        if filters.get('category'):
            q = q.where(Transaction.category == filters['category'])

        if filters.get('start_date'):
            q = q.where(Transaction.transaction_date >= filters['start_date'])

        if filters.get('end_date'):
            q = q.where(Transaction.transaction_date <= filters['end_date'])

        # Execute query
        result = await self.db.execute(q.order_by(Transaction.transaction_date.desc()))
        transactions = result.scalars().all()

        # Calculate summary
        total = sum(t.amount for t in transactions)
        return {
            "transactions": transactions,
            "count": len(transactions),
            "total": total,
            "filters_applied": filters
        }
```

---

### TASK-8.2: Add spending comparison logic
**Priority**: P1
**Effort**: M (5 hours)
**Dependencies**: TASK-8.1
**Description**:
Enable time period comparisons (e.g., "Am I spending more this month vs last month?").

**Acceptance Criteria**:
- [ ] Compare spending between two time periods
- [ ] Support month-over-month, week-over-week, year-over-year
- [ ] Calculate percentage change
- [ ] Break down by category
- [ ] Identify biggest changes
- [ ] Format results for LLM to explain

**Files to Create/Modify**:
- `backend/app/services/chat/spending_comparator.py` (new)

---

### TASK-8.3: Enhance context with all signals
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-2.3
**Description**:
Include ALL behavioral signals in context, not just summary.

**Acceptance Criteria**:
- [ ] Include credit_utilization with details
- [ ] Include income_stability with trend
- [ ] Include spending_surge with category breakdown
- [ ] Include subscription_detected with all subscriptions
- [ ] Include savings_growth with rate
- [ ] Format signals for easy LLM consumption

**Files to Create/Modify**:
- `backend/app/services/chat/context_builder.py` (update)

---

## 9. Guardrails & Safety

### TASK-9.1: Implement content filtering
**Priority**: P0
**Effort**: M (5 hours)
**Dependencies**: TASK-3.1
**Description**:
Filter out prohibited requests before sending to LLM.

**Acceptance Criteria**:
- [ ] Block requests for illegal activities
- [ ] Block requests for specific investment advice
- [ ] Block jailbreak attempts
- [ ] Block abusive language
- [ ] Keyword-based filtering
- [ ] Pattern matching for common violations
- [ ] Log blocked requests for review

**Files to Create/Modify**:
- `backend/app/services/chat/guardrails.py` (new)

**Code Snippet**:
```python
class GuardrailService:
    PROHIBITED_KEYWORDS = [
        "insider trading",
        "pump and dump",
        "money laundering",
        "tax evasion",
        # ... more keywords
    ]

    INVESTMENT_KEYWORDS = [
        "what stock should i buy",
        "which crypto",
        "guaranteed returns",
        # ... more patterns
    ]

    def check_input(self, message: str) -> Dict:
        """Check if message violates guardrails.

        Returns:
            {
                "allowed": bool,
                "reason": str (if not allowed),
                "category": str (if not allowed)
            }
        """
        lower_msg = message.lower()

        # Check for prohibited content
        for keyword in self.PROHIBITED_KEYWORDS:
            if keyword in lower_msg:
                return {
                    "allowed": False,
                    "reason": "This request involves illegal activities",
                    "category": "prohibited"
                }

        # Check for investment advice
        for pattern in self.INVESTMENT_KEYWORDS:
            if pattern in lower_msg:
                return {
                    "allowed": False,
                    "reason": "I can't provide specific investment recommendations. I can explain general concepts instead!",
                    "category": "investment_advice"
                }

        return {"allowed": True}
```

---

### TASK-9.2: Implement response validation
**Priority**: P0
**Effort**: M (4 hours)
**Dependencies**: TASK-9.1
**Description**:
Validate LLM responses to ensure compliance.

**Acceptance Criteria**:
- [ ] Check response for prohibited content
- [ ] Add disclaimers when needed
- [ ] Flag responses for human review if suspicious
- [ ] Log all flagged responses
- [ ] Fallback to generic response if validation fails

**Files to Create/Modify**:
- `backend/app/services/chat/guardrails.py` (update)

---

### TASK-9.3: Add automatic disclaimers
**Priority**: P1
**Effort**: S (2 hours)
**Dependencies**: TASK-9.2
**Description**:
Automatically append disclaimers to certain types of responses.

**Acceptance Criteria**:
- [ ] Detect when response is about investing/taxes/legal
- [ ] Append appropriate disclaimer
- [ ] Don't add duplicate disclaimers
- [ ] Keep disclaimers concise

**Disclaimers**:
- General: "This is educational information only, not financial advice."
- Investment: "Consult a licensed financial advisor before making investment decisions."
- Tax: "For tax questions, please consult a licensed tax professional."

**Files to Create/Modify**:
- `backend/app/services/chat/guardrails.py` (update)

---

## 10. Rate Limiting & Error Handling

### TASK-10.1: Implement rate limiting
**Priority**: P0
**Effort**: M (5 hours)
**Dependencies**: TASK-3.1
**Description**:
Prevent abuse with per-user rate limiting.

**Acceptance Criteria**:
- [ ] Limit: 20 messages per hour per user
- [ ] Use Redis for distributed rate limiting
- [ ] Return 429 status with retry_after header
- [ ] Show user-friendly error message
- [ ] Allow rate limit overrides for premium users (future)
- [ ] Log rate limit violations

**Files to Create/Modify**:
- `backend/app/services/chat/rate_limiter.py` (new)
- `backend/app/api/chat.py` (add rate limit middleware)

**Code Snippet**:
```python
from fastapi import HTTPException, status
import redis
from datetime import datetime, timedelta

class RateLimiter:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.limit = 20  # messages per window
        self.window = 3600  # 1 hour in seconds

    async def check_rate_limit(self, user_id: str) -> Dict:
        """Check if user has exceeded rate limit.

        Returns:
            {
                "allowed": bool,
                "remaining": int,
                "retry_after": int (seconds, if not allowed)
            }
        """
        key = f"rate_limit:chat:{user_id}"

        # Get current count
        count = self.redis.get(key)

        if count is None:
            # First request in window
            self.redis.setex(key, self.window, 1)
            return {"allowed": True, "remaining": self.limit - 1}

        count = int(count)

        if count >= self.limit:
            # Rate limit exceeded
            ttl = self.redis.ttl(key)
            return {
                "allowed": False,
                "remaining": 0,
                "retry_after": ttl
            }

        # Increment count
        self.redis.incr(key)
        return {"allowed": True, "remaining": self.limit - count - 1}
```

---

### TASK-10.2: Improve error handling
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-3.1
**Description**:
Better error messages and graceful degradation.

**Acceptance Criteria**:
- [ ] Specific error messages for each error type
- [ ] User-friendly language (not technical jargon)
- [ ] Retry suggestions when appropriate
- [ ] Log all errors with context
- [ ] Sentry integration for error tracking
- [ ] Fallback responses when LLM fails

**Error Messages**:
- Timeout: "I'm taking longer than usual to respond. Can you try asking again?"
- Rate limit: "You've sent quite a few messages! Please wait {X} minutes before sending more."
- API error: "I'm experiencing technical difficulties. Our team has been notified."
- Invalid input: "I didn't quite understand that. Can you rephrase your question?"

**Files to Create/Modify**:
- `backend/app/services/chat/error_handler.py` (new)

---

### TASK-10.3: Add OpenAI fallback
**Priority**: P2
**Effort**: M (5 hours)
**Dependencies**: TASK-2.2
**Description**:
Use OpenAI as backup when Claude API fails.

**Acceptance Criteria**:
- [ ] Implement OpenAIService class
- [ ] Automatic fallback on Claude timeout/error
- [ ] Log when fallback is used
- [ ] Same interface as ClaudeService
- [ ] Test with real OpenAI API

**Files to Create/Modify**:
- `backend/app/services/llm/openai.py` (implement)
- `backend/app/services/llm/factory.py` (add fallback logic)

---

## 11. Testing Phase 2

### TASK-11.1: Test guardrails with edge cases
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-9.1, TASK-9.2
**Description**:
Comprehensive testing of guardrail system.

**Test Cases**:
- Try to get stock picks
- Ask for illegal advice
- Try jailbreak prompts
- Request tax advice
- Ask about specific crypto to buy
- Test disclaimer addition

**Acceptance Criteria**:
- [ ] All prohibited content blocked
- [ ] Appropriate error messages shown
- [ ] Disclaimers added correctly
- [ ] No false positives on legitimate questions

**Files to Create/Modify**:
- `backend/tests/services/test_guardrails.py` (new)

---

### TASK-11.2: Test rate limiting
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-10.1
**Description**:
Verify rate limiting works correctly.

**Acceptance Criteria**:
- [ ] Send 21 messages in quick succession
- [ ] Verify 21st is blocked with 429
- [ ] Verify retry_after is accurate
- [ ] Verify reset after window expires
- [ ] Test with multiple users (no cross-contamination)

**Files to Create/Modify**:
- `backend/tests/api/test_rate_limiting.py` (new)

---

### TASK-11.3: Test transaction search
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-8.1
**Description**:
Verify transaction search works with various queries.

**Test Queries**:
- "How much did I spend at Starbucks?"
- "Show transactions over $100 last month"
- "What did I buy on Amazon in Q1?"
- "Find all dining transactions this week"

**Acceptance Criteria**:
- [ ] Accurate results for all test queries
- [ ] Correct totals calculated
- [ ] Fuzzy matching works (e.g., "star bucks" matches "Starbucks")
- [ ] Date parsing works correctly

**Files to Create/Modify**:
- `backend/tests/services/test_transaction_search.py` (new)

---

# PHASE 3: UX ENHANCEMENTS (WEEK 3)

## 12. Streaming Responses

### TASK-12.1: Implement SSE streaming endpoint
**Priority**: P1
**Effort**: L (8 hours)
**Dependencies**: TASK-3.1
**Description**:
Add Server-Sent Events endpoint for streaming LLM responses.

**Acceptance Criteria**:
- [ ] POST /chat/stream endpoint
- [ ] Streams response as it generates
- [ ] Sends start/content/end events
- [ ] Handles errors mid-stream
- [ ] Compatible with both Claude and OpenAI streaming APIs
- [ ] Proper content-type headers
- [ ] Works with frontend EventSource

**Files to Create/Modify**:
- `backend/app/api/chat.py` (add stream endpoint)
- `backend/app/services/llm/claude.py` (add streaming method)

**Code Snippet**:
```python
from fastapi.responses import StreamingResponse
import json

@router.post("/stream")
async def stream_message(request: ChatRequest, db: AsyncSession = Depends(get_db)):
    """Stream chat response using SSE."""

    async def event_generator():
        try:
            # Setup (same as /message endpoint)
            # ... validation, context building ...

            conversation_id = request.conversation_id or str(uuid.uuid4())

            # Send start event
            yield f"data: {json.dumps({'type': 'start', 'conversation_id': conversation_id})}\n\n"

            # Stream from LLM
            llm = get_llm_service()
            full_response = ""

            async for chunk in llm.stream_message(system_prompt, user_message, history):
                full_response += chunk
                yield f"data: {json.dumps({'type': 'content', 'delta': chunk})}\n\n"

            # Save to database
            # ... save user and assistant messages ...

            # Send end event
            yield f"data: {json.dumps({'type': 'end', 'tokens_used': tokens})}\n\n"

        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive"
        }
    )
```

---

### TASK-12.2: Update frontend for streaming
**Priority**: P1
**Effort**: M (6 hours)
**Dependencies**: TASK-12.1
**Description**:
Use EventSource to display streaming responses in real-time.

**Acceptance Criteria**:
- [ ] Connect to /chat/stream endpoint
- [ ] Display response as it streams in
- [ ] Smooth typing animation
- [ ] Handle stream errors
- [ ] Fall back to non-streaming on error
- [ ] Close EventSource on unmount
- [ ] Cancel stream on user action

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (update handleSend)

**Code Snippet**:
```typescript
const handleSendStreaming = async () => {
  const userMessage: Message = { /* ... */ };
  setMessages(prev => [...prev, userMessage]);
  setInput('');
  setLoading(true);

  // Create placeholder for assistant message
  const assistantId = (Date.now() + 1).toString();
  const assistantMessage: Message = {
    id: assistantId,
    role: 'assistant',
    content: '',
    timestamp: new Date(),
  };
  setMessages(prev => [...prev, assistantMessage]);

  const eventSource = new EventSource(
    `${API_BASE}/chat/stream?user_id=${userId}&message=${encodeURIComponent(input)}`
  );

  eventSource.onmessage = (event) => {
    const data = JSON.parse(event.data);

    if (data.type === 'start') {
      setConversationId(data.conversation_id);
    } else if (data.type === 'content') {
      // Append delta to message
      setMessages(prev =>
        prev.map(msg =>
          msg.id === assistantId
            ? { ...msg, content: msg.content + data.delta }
            : msg
        )
      );
    } else if (data.type === 'end') {
      eventSource.close();
      setLoading(false);
    } else if (data.type === 'error') {
      eventSource.close();
      setLoading(false);
      // Show error
    }
  };

  eventSource.onerror = () => {
    eventSource.close();
    setLoading(false);
    // Fallback to non-streaming
  };
};
```

---

## 13. Conversation History UI

### TASK-13.1: Create conversation history component
**Priority**: P1
**Effort**: M (6 hours)
**Dependencies**: TASK-3.2
**Description**:
Build UI to view past conversations.

**Acceptance Criteria**:
- [ ] List all conversations with topics and dates
- [ ] Click to view full conversation
- [ ] Search conversations
- [ ] Delete conversations
- [ ] Responsive design
- [ ] Loading states
- [ ] Empty state ("No conversations yet")

**Files to Create/Modify**:
- `frontend/src/components/user/ConversationHistory.tsx` (new)
- `frontend/src/components/user/FinancialChatbot.tsx` (add "History" button)

---

### TASK-13.2: Add "New Conversation" button
**Priority**: P2
**Effort**: XS (1 hour)
**Dependencies**: TASK-4.2
**Description**:
Allow users to start fresh conversation.

**Acceptance Criteria**:
- [ ] Button to clear current conversation
- [ ] Generates new conversation_id
- [ ] Confirmation dialog ("Start new conversation?")
- [ ] Clear messages from state

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (add button)

---

## 14. Suggested Questions

### TASK-14.1: Implement smart question suggestions
**Priority**: P1
**Effort**: M (5 hours)
**Dependencies**: TASK-4.2
**Description**:
Generate personalized suggested questions based on user's data.

**Acceptance Criteria**:
- [ ] Analyze user's signals to generate relevant questions
- [ ] Show 3-5 suggested questions
- [ ] Update suggestions as conversation progresses
- [ ] Click to auto-fill question
- [ ] Different suggestions for new vs returning users

**Example Logic**:
- If high credit utilization â†’ "How can I improve my credit score?"
- If spending surge in category â†’ "Why is my {category} spending higher?"
- If new subscriptions detected â†’ "What subscriptions do I have?"
- If low savings â†’ "How can I save more money?"

**Files to Create/Modify**:
- `backend/app/services/chat/question_suggester.py` (new)
- `frontend/src/components/user/FinancialChatbot.tsx` (update quick questions)

---

### TASK-14.2: Add question templates
**Priority**: P2
**Effort**: S (2 hours)
**Dependencies**: TASK-14.1
**Description**:
Pre-written question templates for common scenarios.

**Templates**:
- "How much did I spend on [category] this month?"
- "Show me my [merchant] transactions"
- "Am I on track with my budget?"
- "What's my biggest expense?"
- "How can I improve my credit score?"

**Files to Create/Modify**:
- `backend/app/services/chat/question_templates.py` (new)

---

## 15. Response Actions

### TASK-15.1: Add "View Transactions" action
**Priority**: P2
**Effort**: M (4 hours)
**Dependencies**: TASK-4.2
**Description**:
When chatbot mentions transactions, show button to view them.

**Acceptance Criteria**:
- [ ] Detect when response references specific transactions
- [ ] Show "View Transactions" button
- [ ] Opens transaction list filtered to mentioned transactions
- [ ] Pass filters via URL params or state

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (add action buttons)
- Extract transaction IDs or filters from response

---

### TASK-15.2: Add "View Recommendation" action
**Priority**: P2
**Effort**: S (3 hours)
**Dependencies**: TASK-4.2
**Description**:
Link to recommendation detail when mentioned in chat.

**Acceptance Criteria**:
- [ ] Detect when response references recommendation
- [ ] Show "View Recommendation" button
- [ ] Opens recommendation detail modal/page
- [ ] Highlight referenced recommendation

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (add action)

---

### TASK-15.3: Add "Create Budget" action
**Priority**: P3
**Effort**: M (4 hours)
**Dependencies**: TASK-4.2
**Description**:
When chatbot suggests budget, show button to create one.

**Acceptance Criteria**:
- [ ] Detect budget-related responses
- [ ] Pre-fill budget form with suggested values from chat
- [ ] Show "Create Budget" button
- [ ] Opens budget creation flow

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (add action)

---

## 16. Polish & UX Improvements

### TASK-16.1: Improve typing indicator
**Priority**: P3
**Effort**: XS (1 hour)
**Dependencies**: TASK-4.2
**Description**:
Better typing animation while waiting for response.

**Acceptance Criteria**:
- [ ] Animated dots
- [ ] Show avatar/icon
- [ ] Contextual message ("Analyzing...", "Thinking...")

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (update loading state)

---

### TASK-16.2: Add markdown formatting
**Priority**: P2
**Effort**: S (2 hours)
**Dependencies**: TASK-4.2
**Description**:
Render markdown in chat responses (bold, bullets, etc.).

**Acceptance Criteria**:
- [ ] Install markdown parser (marked or react-markdown)
- [ ] Render bold, italic, bullets, numbered lists
- [ ] Sanitize HTML to prevent XSS
- [ ] Style markdown elements to match design

**Files to Create/Modify**:
- `frontend/package.json` (add react-markdown)
- `frontend/src/components/user/FinancialChatbot.tsx` (render markdown)

---

### TASK-16.3: Add message timestamps
**Priority**: P3
**Effort**: XS (1 hour)
**Dependencies**: TASK-4.2
**Description**:
Show clearer timestamps on messages.

**Acceptance Criteria**:
- [ ] Show relative time ("2 min ago", "Yesterday")
- [ ] Tooltip with absolute time on hover
- [ ] Group messages by day with date separators

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (update timestamp display)

---

### TASK-16.4: Improve error messages
**Priority**: P2
**Effort**: S (2 hours)
**Dependencies**: TASK-4.2
**Description**:
Better UX for error states.

**Acceptance Criteria**:
- [ ] Friendly error messages (not technical)
- [ ] Retry button for failed messages
- [ ] Different icons for different error types
- [ ] Clear visual distinction from normal messages

**Files to Create/Modify**:
- `frontend/src/components/user/FinancialChatbot.tsx` (update error handling)

---

## 17. Testing Phase 3

### TASK-17.1: Test streaming performance
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-12.1, TASK-12.2
**Description**:
Verify streaming works smoothly and efficiently.

**Acceptance Criteria**:
- [ ] No lag or stuttering in UI
- [ ] Proper error handling if stream drops
- [ ] Memory doesn't leak with long conversations
- [ ] Works on slow connections (3G simulation)

---

### TASK-17.2: Test conversation history
**Priority**: P1
**Effort**: S (2 hours)
**Dependencies**: TASK-13.1
**Description**:
Verify conversation history UI works correctly.

**Acceptance Criteria**:
- [ ] Can view past conversations
- [ ] Search works
- [ ] Delete works
- [ ] Pagination works (if many conversations)
- [ ] No data shown for other users (privacy)

---

### TASK-17.3: Accessibility testing
**Priority**: P2
**Effort**: S (3 hours)
**Dependencies**: All UI tasks
**Description**:
Ensure chat is accessible to all users.

**Acceptance Criteria**:
- [ ] Keyboard navigation works (Tab, Enter, Esc)
- [ ] Screen reader compatible (ARIA labels)
- [ ] Focus management (auto-focus input after send)
- [ ] High contrast mode support
- [ ] No color-only indicators

**Tools**:
- Use axe DevTools for automated testing
- Manual testing with screen reader

---

# PHASE 4: ANALYTICS & OPTIMIZATION (WEEK 4)

## 18. Analytics & Monitoring

### TASK-18.1: Create analytics events
**Priority**: P0
**Effort**: M (4 hours)
**Dependencies**: TASK-3.1
**Description**:
Track key events for analytics.

**Events to Track**:
- chat_message_sent (user_id, conversation_id, message_length)
- chat_response_received (user_id, tokens_used, response_time_ms, model)
- chat_feedback_submitted (user_id, message_id, rating)
- chat_error (user_id, error_type, error_message)
- rate_limit_hit (user_id)
- guardrail_triggered (user_id, reason)

**Acceptance Criteria**:
- [ ] Events sent to analytics platform (Mixpanel, Amplitude, or custom)
- [ ] Include relevant metadata
- [ ] Privacy-safe (no PII in events)
- [ ] Batching for efficiency

**Files to Create/Modify**:
- `backend/app/services/analytics/events.py` (new)
- `backend/app/api/chat.py` (add event tracking)

---

### TASK-18.2: Create analytics dashboard
**Priority**: P1
**Effort**: L (6 hours)
**Dependencies**: TASK-18.1
**Description**:
Build internal dashboard to monitor chat metrics.

**Metrics to Display**:
- Daily active chat users
- Messages per session (avg, median, p95)
- Response times (p50, p95, p99)
- Error rate
- User satisfaction (thumbs up %)
- Most common questions (topic clustering)
- Token usage and costs
- Rate limit hits

**Acceptance Criteria**:
- [ ] Dashboard accessible to operators
- [ ] Real-time or near real-time updates
- [ ] Date range filtering
- [ ] Export to CSV
- [ ] Visualizations (charts/graphs)

**Files to Create/Modify**:
- `frontend/src/components/operator/ChatAnalyticsDashboard.tsx` (new)
- `backend/app/api/analytics.py` (new endpoints)

---

### TASK-18.3: Set up monitoring and alerts
**Priority**: P0
**Effort**: M (5 hours)
**Dependencies**: TASK-18.1
**Description**:
Monitor system health and alert on issues.

**Alerts to Configure**:
- Error rate > 5% (5 min window) â†’ Critical
- Response time p95 > 10s (5 min window) â†’ Warning
- API costs > $100/hour â†’ Warning
- Rate limit hit rate > 20% of users â†’ Warning

**Tools**:
- Use Datadog, New Relic, or Prometheus + Grafana
- PagerDuty for alerts

**Acceptance Criteria**:
- [ ] Alerts configured and tested
- [ ] On-call rotation set up
- [ ] Runbook for common issues
- [ ] Dashboard for system health

**Files to Create/Modify**:
- `backend/app/services/monitoring/metrics.py` (new)
- Configuration files for monitoring tools

---

### TASK-18.4: Implement logging
**Priority**: P0
**Effort**: S (3 hours)
**Dependencies**: TASK-3.1
**Description**:
Comprehensive logging for debugging and compliance.

**What to Log**:
- All chat requests (user_id, timestamp, conversation_id)
- LLM requests/responses (tokens, model, response time)
- Errors with stack traces
- Guardrail triggers
- Rate limit violations

**What NOT to Log**:
- Full message content (PII concerns)
- API keys
- User passwords/tokens

**Acceptance Criteria**:
- [ ] Structured logging (JSON format)
- [ ] Log levels (DEBUG, INFO, WARNING, ERROR)
- [ ] Log rotation
- [ ] Centralized logging (CloudWatch, ELK, or similar)

**Files to Create/Modify**:
- `backend/app/logging_config.py` (new)
- Update all services to use logger

---

## 19. Performance Optimization

### TASK-19.1: Implement response caching
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-3.1
**Description**:
Cache common responses to reduce LLM API calls.

**Acceptance Criteria**:
- [ ] Cache based on question similarity (embeddings or hash)
- [ ] 10 min TTL for cached responses
- [ ] Cache hit/miss tracking
- [ ] Invalidate cache on user data changes
- [ ] Only cache for non-personalized questions

**Files to Create/Modify**:
- `backend/app/services/chat/cache.py` (new)

---

### TASK-19.2: Optimize context building
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: TASK-2.3
**Description**:
Reduce token usage and improve context build performance.

**Optimizations**:
- [ ] Cache user profile (1 min TTL)
- [ ] Parallel data fetching (asyncio.gather)
- [ ] Reduce transaction limit from 20 to 15 (test impact)
- [ ] Summarize old signals instead of including full details
- [ ] Compress context text (remove unnecessary words)

**Acceptance Criteria**:
- [ ] Context build time < 200ms (p95)
- [ ] Token reduction of 20-30%
- [ ] No loss in response quality

**Files to Create/Modify**:
- `backend/app/services/chat/context_builder.py` (optimize)

---

### TASK-19.3: Database query optimization
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: TASK-1.1
**Description**:
Optimize database queries for chat endpoints.

**Optimizations**:
- [ ] Add indexes on frequently queried fields
- [ ] Use select_related/joinedload for relationships
- [ ] Batch queries where possible
- [ ] Add database connection pooling
- [ ] Query result caching

**Acceptance Criteria**:
- [ ] All queries < 50ms (p95)
- [ ] No N+1 query problems
- [ ] Explain plan reviewed for all queries

**Files to Create/Modify**:
- Migration files for new indexes
- Update queries in context_builder.py

---

### TASK-19.4: Implement request queuing
**Priority**: P2
**Effort**: M (5 hours)
**Dependencies**: TASK-3.1
**Description**:
Queue requests during high load to prevent API overload.

**Acceptance Criteria**:
- [ ] Use Celery or similar for background processing
- [ ] Queue requests when load > threshold
- [ ] Return estimated wait time to user
- [ ] Process queue in FIFO order
- [ ] Monitor queue length

**Files to Create/Modify**:
- `backend/app/workers/chat_worker.py` (new)
- `backend/app/api/chat.py` (add queuing logic)

---

## 20. A/B Testing Framework

### TASK-20.1: Implement prompt A/B testing
**Priority**: P2
**Effort**: M (5 hours)
**Dependencies**: TASK-2.4
**Description**:
Framework to test different prompt versions.

**Acceptance Criteria**:
- [ ] Randomly assign users to prompt variants
- [ ] Track which variant each conversation uses
- [ ] Collect satisfaction metrics by variant
- [ ] Admin UI to create new variants
- [ ] Statistical significance testing

**Files to Create/Modify**:
- `backend/app/services/chat/ab_testing.py` (new)
- `backend/app/api/chat.py` (integrate A/B logic)

---

### TASK-20.2: Test different response styles
**Priority**: P2
**Effort**: S (3 hours)
**Dependencies**: TASK-20.1
**Description**:
A/B test different tone/style in prompts.

**Variants to Test**:
- Variant A: Friendly & casual
- Variant B: Professional & formal
- Variant C: Concise & data-focused

**Acceptance Criteria**:
- [ ] 3 prompt variants created
- [ ] 1 week test duration
- [ ] Measure user satisfaction and engagement
- [ ] Document results

---

## 21. Documentation & Handoff

### TASK-21.1: Write comprehensive API docs
**Priority**: P1
**Effort**: M (4 hours)
**Dependencies**: All backend tasks
**Description**:
Complete API documentation for all chat endpoints.

**Acceptance Criteria**:
- [ ] All endpoints documented
- [ ] Request/response schemas
- [ ] Error codes and meanings
- [ ] Rate limiting details
- [ ] Authentication requirements
- [ ] Code examples (curl, Python, TypeScript)
- [ ] Interactive API explorer (Swagger UI)

**Files to Create/Modify**:
- `backend/docs/api/chat_v1.md` (new)
- Update OpenAPI spec

---

### TASK-21.2: Write operator runbook
**Priority**: P0
**Effort**: M (4 hours)
**Dependencies**: All Phase 4 tasks
**Description**:
Operations manual for maintaining the chat system.

**Sections**:
- Architecture overview
- Deployment process
- Monitoring & alerts
- Common issues & troubleshooting
- Scaling guide
- Cost management
- Incident response

**Acceptance Criteria**:
- [ ] Step-by-step troubleshooting guides
- [ ] Screenshots of dashboards
- [ ] Contact info for escalations
- [ ] Tested by non-author

**Files to Create/Modify**:
- `backend/docs/operations/chat_runbook.md` (new)

---

### TASK-21.3: Create developer guide
**Priority**: P1
**Effort**: S (3 hours)
**Dependencies**: All tasks
**Description**:
Guide for developers to understand and extend the chat system.

**Sections**:
- Architecture deep dive
- How to add new features
- How to modify prompts
- How to add new LLM providers
- Testing guide
- Code walkthrough

**Files to Create/Modify**:
- `backend/docs/development/chat_developer_guide.md` (new)

---

### TASK-21.4: Create user guide
**Priority**: P2
**Effort**: S (2 hours)
**Dependencies**: All frontend tasks
**Description**:
Help documentation for end users.

**Sections**:
- What is the AI assistant?
- How to use it
- Example questions
- Privacy & data usage
- FAQ
- Tips for best results

**Files to Create/Modify**:
- `docs/user/chat_user_guide.md` (new)

---

## 22. Final Testing & Launch Prep

### TASK-22.1: End-to-end testing
**Priority**: P0
**Effort**: L (6 hours)
**Dependencies**: All tasks
**Description**:
Comprehensive E2E testing of entire system.

**Test Scenarios**:
- Complete user journey (open chat â†’ ask questions â†’ get help â†’ rate response)
- Multi-turn conversations
- Error recovery
- Performance under load
- Cross-browser testing (Chrome, Firefox, Safari)
- Mobile testing (iOS, Android)

**Acceptance Criteria**:
- [ ] All critical paths tested
- [ ] No blocking bugs
- [ ] Performance meets targets
- [ ] Test report documented

---

### TASK-22.2: Security audit
**Priority**: P0
**Effort**: M (5 hours)
**Dependencies**: All tasks
**Description**:
Security review before launch.

**Checks**:
- [ ] API keys not exposed
- [ ] Input sanitization
- [ ] SQL injection prevention
- [ ] XSS prevention
- [ ] CSRF protection
- [ ] Rate limiting works
- [ ] Authentication/authorization correct
- [ ] Data encryption at rest and in transit

**Tools**:
- OWASP ZAP for automated scanning
- Manual penetration testing

---

### TASK-22.3: Load testing
**Priority**: P0
**Effort**: M (4 hours)
**Dependencies**: All tasks
**Description**:
Stress test to ensure system handles production load.

**Tests**:
- [ ] 100 concurrent users
- [ ] 1000 requests per minute sustained
- [ ] Spike test (sudden 10x load)
- [ ] Soak test (24 hours at normal load)

**Acceptance Criteria**:
- [ ] No crashes or errors
- [ ] Response times within targets
- [ ] Database handles load
- [ ] LLM API doesn't hit rate limits

**Tools**:
- locust or k6 for load testing

---

### TASK-22.4: Beta launch
**Priority**: P0
**Effort**: L (8 hours)
**Dependencies**: All tasks
**Description**:
Limited release to 10% of users for validation.

**Steps**:
1. Deploy to production with feature flag
2. Enable for 10% of users
3. Monitor metrics closely (24/7 on-call)
4. Collect user feedback
5. Fix any critical issues
6. Iterate based on feedback

**Acceptance Criteria**:
- [ ] Feature flag configured
- [ ] User selection random and stable
- [ ] Rollback plan tested
- [ ] Metrics dashboard live
- [ ] Feedback collection active
- [ ] No critical bugs in first 48 hours

**Duration**: 1 week

---

### TASK-22.5: Full launch
**Priority**: P0
**Effort**: M (4 hours)
**Dependencies**: TASK-22.4
**Description**:
Roll out to 100% of users.

**Steps**:
1. Review beta metrics and feedback
2. Fix any remaining issues
3. Prepare announcement (email, in-app, social)
4. Gradually roll out (10% â†’ 25% â†’ 50% â†’ 100%)
5. Monitor closely during rollout
6. Celebrate! ðŸŽ‰

**Acceptance Criteria**:
- [ ] All beta issues resolved
- [ ] Marketing materials ready
- [ ] Support team trained
- [ ] Monitoring in place
- [ ] Successful rollout to 100%

---

# SUMMARY

## Task Statistics

**Phase 1 (Week 1)**: 19 tasks
**Phase 2 (Week 2)**: 14 tasks
**Phase 3 (Week 3)**: 17 tasks
**Phase 4 (Week 4)**: 19 tasks

**Total**: 69 tasks

## Effort Breakdown

- XS (1-2 hrs): 12 tasks = 18 hours
- S (2-4 hrs): 20 tasks = 60 hours
- M (4-8 hrs): 26 tasks = 156 hours
- L (1-2 days): 9 tasks = 108 hours
- XL (2-5 days): 2 tasks = 24 hours

**Total Estimated Hours**: ~366 hours (~9 weeks for 1 developer, ~2.5 weeks for 4 developers)

## Critical Path

P0 tasks must complete first:
1. TASK-1.1, 1.3 (Database)
2. TASK-2.1, 2.2, 2.3, 2.4 (LLM Integration)
3. TASK-3.1 (Chat endpoint)
4. TASK-4.1, 4.2 (Frontend)
5. Phase 2-4 build on top of Phase 1 foundation

## Success Criteria for Launch

- âœ… All P0 tasks completed
- âœ… All P1 tasks completed
- âœ… Security audit passed
- âœ… Load testing passed
- âœ… Beta metrics positive (>80% satisfaction)
- âœ… Response time < 3s (p95)
- âœ… Error rate < 2%
- âœ… Documentation complete

---

**Document Version**: 1.0
**Last Updated**: 2025-11-05
**Author**: AI Product Team
